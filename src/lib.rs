/// `OpenAI` API client library
#[macro_use]
extern crate derive_builder;
#[macro_use]
extern crate maybe_async;

use thiserror::Error;

type Result<T> = std::result::Result<T, Error>;

#[allow(clippy::default_trait_access)]
pub mod api {
    //! Data types corresponding to requests and responses from the API
    use std::{collections::HashMap, convert::TryFrom, fmt::Display};

    use serde::{Deserialize, Serialize};

    /// Container type. Used in the api, but not useful for clients of this library
    #[derive(Deserialize, Debug)]
    pub(crate) struct Container<T> {
        /// Items in the page's results
        pub data: Vec<T>,
    }

    /// Detailed information on a particular engine.
    #[derive(Deserialize, Debug, Eq, PartialEq, Clone)]
    pub struct EngineInfo {
        /// The name of the engine, e.g. `"davinci"` or `"ada"`
        pub id: String,
        /// The owner of the model. Usually (always?) `"openai"`
        pub owner: String,
        /// Whether the model is ready for use. Usually (always?) `true`
        pub ready: bool,
    }

    /// Options for the query completion
    #[derive(Serialize, Debug, Builder, Clone)]
    #[builder(pattern = "immutable")]
    pub struct CompletionArgs {
        /// The id of the engine to use for this request
        ///
        /// # Example
        /// ```
        /// # use openai_api::api::CompletionArgs;
        /// CompletionArgs::builder().engine("davinci");
        /// ```
        #[builder(setter(into), default = "\"davinci\".into()")]
        #[serde(skip_serializing)]
        pub(super) engine: String,
        /// The prompt to complete from.
        ///
        /// Defaults to `"<|endoftext|>"` which is a special token seen during training.
        ///
        /// # Example
        /// ```
        /// # use openai_api::api::CompletionArgs;
        /// CompletionArgs::builder().prompt("Once upon a time...");
        /// ```
        #[builder(setter(into), default = "\"<|endoftext|>\".into()")]
        prompt: String,
        /// Maximum number of tokens to complete.
        ///
        /// Defaults to 16
        /// # Example
        /// ```
        /// # use openai_api::api::CompletionArgs;
        /// CompletionArgs::builder().max_tokens(64);
        /// ```
        #[builder(default = "16")]
        max_tokens: u64,
        /// What sampling temperature to use.
        ///
        /// Default is `1.0`
        ///
        /// Higher values means the model will take more risks.
        /// Try 0.9 for more creative applications, and 0 (argmax sampling)
        /// for ones with a well-defined answer.
        ///
        /// OpenAI recommends altering this or top_p but not both.
        ///
        /// # Example
        /// ```
        /// # use openai_api::api::{CompletionArgs, CompletionArgsBuilder};
        /// # use std::convert::{TryInto, TryFrom};
        /// # fn main() -> anyhow::Result<()> {
        /// let builder = CompletionArgs::builder().temperature(0.7);
        /// let args: CompletionArgs = builder.try_into()?;
        /// # Ok::<(), anyhow::Error>(())
        /// # }
        /// ```
        #[builder(default = "1.0")]
        temperature: f64,
        #[builder(default = "1.0")]
        top_p: f64,
        #[builder(default = "1")]
        n: u64,
        #[builder(setter(strip_option), default)]
        logprobs: Option<u64>,
        #[builder(default = "false")]
        echo: bool,
        #[builder(setter(strip_option), default)]
        stop: Option<Vec<String>>,
        #[builder(default = "0.0")]
        presence_penalty: f64,
        #[builder(default = "0.0")]
        frequency_penalty: f64,
        #[builder(default)]
        logit_bias: HashMap<String, f64>,
    }

    // TODO: add validators for the different arguments

    impl From<&str> for CompletionArgs {
        fn from(prompt_string: &str) -> Self {
            Self {
                prompt: prompt_string.into(),
                ..CompletionArgsBuilder::default()
                    .build()
                    .expect("default should build")
            }
        }
    }

    impl CompletionArgs {
        /// Build a `CompletionArgs` from the defaults
        #[must_use]
        pub fn builder() -> CompletionArgsBuilder {
            CompletionArgsBuilder::default()
        }
    }

    impl TryFrom<CompletionArgsBuilder> for CompletionArgs {
        type Error = CompletionArgsBuilderError;

        fn try_from(builder: CompletionArgsBuilder) -> Result<Self, Self::Error> {
            builder.build()
        }
    }
    /// Represents a non-streamed completion response
    #[derive(Deserialize, Debug, Clone)]
    pub struct Completion {
        /// Completion unique identifier
        pub id: String,
        /// Unix timestamp when the completion was generated
        pub created: u64,
        /// Exact model type and version used for the completion
        pub model: String,
        /// List of completions generated by the model
        pub choices: Vec<Choice>,
    }

    impl std::fmt::Display for Completion {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            write!(f, "{}", self.choices[0])
        }
    }

    /// A single completion result
    #[derive(Deserialize, Debug, Clone)]
    pub struct Choice {
        /// The text of the completion. Will contain the prompt if echo is True.
        pub text: String,
        /// Offset in the result where the completion began. Useful if using echo.
        pub index: u64,
        /// If requested, the log probabilities of the completion tokens
        pub logprobs: Option<LogProbs>,
        /// Why the completion ended when it did
        pub finish_reason: String,
    }

    impl std::fmt::Display for Choice {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            self.text.fmt(f)
        }
    }

    /// Represents a logprobs subdocument
    #[derive(Deserialize, Debug, Clone)]
    pub struct LogProbs {
        pub tokens: Vec<String>,
        pub token_logprobs: Vec<Option<f64>>,
        pub top_logprobs: Vec<Option<HashMap<String, f64>>>,
        pub text_offset: Vec<u64>,
    }

    /// Error response object from the server
    #[derive(Deserialize, Debug, Eq, PartialEq, Clone)]
    pub struct ErrorMessage {
        pub message: String,
        #[serde(rename = "type")]
        pub error_type: String,
    }

    impl Display for ErrorMessage {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            self.message.fmt(f)
        }
    }

    /// API-level wrapper used in deserialization
    #[derive(Deserialize, Debug)]
    pub(crate) struct ErrorWrapper {
        pub error: ErrorMessage,
    }
}

/// This library's main `Error` type.
#[derive(Error, Debug)]
pub enum Error {
    /// An error returned by the API itself
    #[error("API returned an Error: {}", .0.message)]
    Api(api::ErrorMessage),
    /// An error the client discovers before talking to the API
    #[error("Bad arguments: {0}")]
    BadArguments(String),
    /// Network / protocol related errors
    #[cfg(feature = "is_async")]
    #[error("Error at the protocol level: {0}")]
    Protocol(surf::Error),
    #[cfg(feature = "is_sync")]
    #[error("Error at the protocol level, sync client")]
    Protocol(ureq::Error),
}

impl From<api::ErrorMessage> for Error {
    fn from(e: api::ErrorMessage) -> Self {
        Error::Api(e)
    }
}

impl From<String> for Error {
    fn from(e: String) -> Self {
        Error::BadArguments(e)
    }
}

#[cfg(feature = "is_async")]
impl From<surf::Error> for Error {
    fn from(e: surf::Error) -> Self {
        Error::Protocol(e)
    }
}

#[cfg(feature = "is_sync")]
impl From<ureq::Error> for Error {
    fn from(e: ureq::Error) -> Self {
        Error::Protocol(e)
    }
}

#[cfg(feature = "is_async")]
mod bearer {
    /// Authentication middleware
    pub(crate) struct BearerToken {
        token: String,
    }

    impl std::fmt::Debug for BearerToken {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            // Get the first few characters to help debug, but not accidentally log key
            write!(
                f,
                r#"Bearer {{ token: "{}" }}"#,
                self.token.get(0..8).ok_or(std::fmt::Error)?
            )
        }
    }

    impl BearerToken {
        pub fn new(token: &str) -> Self {
            Self {
                token: String::from(token),
            }
        }
    }

    #[surf::utils::async_trait]
    impl surf::middleware::Middleware for BearerToken {
        async fn handle(
            &self,
            mut req: surf::Request,
            client: surf::Client,
            next: surf::middleware::Next<'_>,
        ) -> surf::Result<surf::Response> {
            log::debug!("Request: {:?}", req);
            req.insert_header("Authorization", format!("Bearer {}", self.token));
            let response: surf::Response = next.run(req, client).await?;
            log::debug!("Response: {:?}", response);
            Ok(response)
        }
    }
}

#[async_impl]
fn client(token: &str, base_url: &str) -> surf::Client {
    let mut async_client = surf::client();
    async_client.set_base_url(surf::Url::parse(base_url).expect("Static string should parse"));
    async_client.with(bearer::BearerToken::new(token))
}

#[sync_impl]
fn client(token: &str, _base_url: &str) -> ureq::Agent {
    ureq::agent().auth_kind("Bearer", token).build()
}

/// Client object. Must be constructed to talk to the API.
#[derive(Debug, Clone)]
pub struct Client {
    #[cfg(feature = "is_async")]
    client: surf::Client,
    #[cfg(feature = "is_sync")]
    client: ureq::Agent,
    base_url: String,
}

impl Client {
    // Creates a new `Client` given an api token
    #[must_use]
    pub fn new(token: &str) -> Self {
        let base_url: String = "https://api.openai.com/v1/".into();
        Self {
            client: client(token, &base_url),
            base_url,
        }
    }

    // Allow setting the api root in the tests
    #[cfg(test)]
    pub fn set_api_root(&mut self, base_url: String) {
        #[cfg(feature = "is_async")]
        {
            self.client.set_base_url(
                surf::Url::parse(&base_url).expect("static URL expected to parse correctly"),
            );
        }
        self.base_url = base_url;
    }

    /// Private helper for making gets
    #[maybe_async::async_impl]
    async fn get<T>(&self, endpoint: &str) -> Result<T>
    where
        T: serde::de::DeserializeOwned,
    {
        let mut response = self.client.get(endpoint).await?;
        if let surf::StatusCode::Ok = response.status() {
            Ok(response.body_json::<T>().await?)
        } else {
            let err = response.body_json::<api::ErrorWrapper>().await?.error;
            Err(Error::Api(err))
        }
    }

    #[maybe_async::sync_impl]
    fn get<T>(&self, endpoint: &str) -> Result<T>
    where
        T: serde::de::DeserializeOwned,
    {
        let response = dbg!(self.client.get(&format!("{}{}", self.base_url, endpoint))).call();
        if let 200 = response.status() {
            Ok(response
                .into_json_deserialize()
                .expect("Bug: client couldn't deserialize api response"))
        } else {
            let err = response
                .into_json_deserialize::<api::ErrorWrapper>()
                .expect("Bug: client couldn't deserialize api error response")
                .error;
            Err(Error::Api(err))
        }
    }

    /// Lists the currently available engines.
    ///
    /// Provides basic information about each one such as the owner and availability.
    ///
    /// # Errors
    /// - `Error::APIError` if the server returns an error
    #[maybe_async::maybe_async]
    pub async fn engines(&self) -> Result<Vec<api::EngineInfo>> {
        self.get("engines").await.map(|r: api::Container<_>| r.data)
    }

    /// Retrieves an engine instance
    ///
    /// Provides basic information about the engine such as the owner and availability.
    ///
    /// # Errors
    /// - `Error::APIError` if the server returns an error
    #[maybe_async::maybe_async]
    pub async fn engine(&self, engine: &str) -> Result<api::EngineInfo> {
        self.get(&format!("engines/{}", engine)).await
    }

    // Private helper to generate post requests. Needs to be a bit more flexible than
    // get because it should support SSE eventually
    #[maybe_async::async_impl]
    async fn post<B, R>(&self, endpoint: &str, body: B) -> Result<R>
    where
        B: serde::ser::Serialize,
        R: serde::de::DeserializeOwned,
    {
        let mut response = self
            .client
            .post(endpoint)
            .body(surf::Body::from_json(&body)?)
            .await?;
        match response.status() {
            surf::StatusCode::Ok => Ok(response.body_json::<R>().await?),
            _ => Err(Error::Api(
                response
                    .body_json::<api::ErrorWrapper>()
                    .await
                    .expect("The API has returned something funky")
                    .error,
            )),
        }
    }

    #[maybe_async::sync_impl]
    fn post<B, R>(&self, endpoint: &str, body: B) -> Result<R>
    where
        B: serde::ser::Serialize,
        R: serde::de::DeserializeOwned,
    {
        let response = self
            .client
            .post(&format!("{}{}", self.base_url, endpoint))
            .send_json(
                serde_json::to_value(body).expect("Bug: client couldn't serialize its own type"),
            );
        match response.status() {
            200 => Ok(response
                .into_json_deserialize()
                .expect("Bug: client couldn't deserialize api response")),
            _ => Err(Error::Api(
                response
                    .into_json_deserialize::<api::ErrorWrapper>()
                    .expect("Bug: client couldn't deserialize api error response")
                    .error,
            )),
        }
    }

    /// Get predicted completion of the prompt
    ///
    /// # Errors
    ///  - `Error::APIError` if the api returns an error
    #[maybe_async::maybe_async]
    pub async fn complete_prompt(
        &self,
        prompt: impl Into<api::CompletionArgs>,
    ) -> Result<api::Completion> {
        let args = prompt.into();
        Ok(self
            .post(&format!("engines/{}/completions", args.engine), args)
            .await?)
    }
}
#[cfg(test)]
mod unit {

    use crate::{api, Client, Error};

    fn mocked_client() -> Client {
        let _ = env_logger::builder().is_test(true).try_init();
        let mut client = Client::new("bogus");
        client.set_api_root(format!("{}/", mockito::server_url()).to_owned());
        client
    }

    #[cfg(feature = "is_async")]
    #[tokio::test]
    async fn can_create_client() {
        let _c = mocked_client();
    }

    #[cfg(feature = "is_sync")]
    #[test]
    fn can_create_client() {
        let _c = mocked_client();
    }

    #[cfg(feature = "is_async")]
    #[tokio::test]
    async fn parse_engine_info() -> Result<(), Box<dyn std::error::Error>> {
        let example = r#"{
            "id": "ada",
            "object": "engine",
            "owner": "openai",
            "ready": true
        }"#;
        let ei: api::EngineInfo = serde_json::from_str(example)?;
        assert_eq!(
            ei,
            api::EngineInfo {
                id: "ada".into(),
                owner: "openai".into(),
                ready: true,
            }
        );
        Ok(())
    }

    #[cfg(feature = "is_async")]
    #[tokio::test]
    async fn parse_engines() {
        use api::EngineInfo;
        let mock = mockito::mock("GET", "/engines")
            .with_status(200)
            .with_header("content-type", "application/json")
            .with_body(
                r#"{
            "object": "list",
            "data": [
              {
                "id": "ada",
                "object": "engine",
                "owner": "openai",
                "ready": true
              },
              {
                "id": "babbage",
                "object": "engine",
                "owner": "openai",
                "ready": true
              },
              {
                "id": "experimental-engine-v7",
                "object": "engine",
                "owner": "openai",
                "ready": false
              },
              {
                "id": "curie",
                "object": "engine",
                "owner": "openai",
                "ready": true
              },
              {
                "id": "davinci",
                "object": "engine",
                "owner": "openai",
                "ready": true
              },
              {
                 "id": "content-filter-alpha-c4",
                 "object": "engine",
                 "owner": "openai",
                 "ready": true
              }
            ]
          }"#,
            )
            .create();

        let expected = vec![
            EngineInfo {
                id: "ada".into(),
                owner: "openai".into(),
                ready: true,
            },
            EngineInfo {
                id: "babbage".into(),
                owner: "openai".into(),
                ready: true,
            },
            EngineInfo {
                id: "experimental-engine-v7".into(),
                owner: "openai".into(),
                ready: false,
            },
            EngineInfo {
                id: "curie".into(),
                owner: "openai".into(),
                ready: true,
            },
            EngineInfo {
                id: "davinci".into(),
                owner: "openai".into(),
                ready: true,
            },
            EngineInfo {
                id: "content-filter-alpha-c4".into(),
                owner: "openai".into(),
                ready: true,
            },
        ];
        let response = mocked_client().engines().await.unwrap();
        assert_eq!(response, expected);
        mock.assert()
    }

    #[cfg(feature = "is_async")]
    #[tokio::test]
    async fn engine_error_response() {
        let mock = mockito::mock("GET", "/engines/davinci")
            .with_status(404)
            .with_header("content-type", "application/json")
            .with_body(
                r#"{
                "error": {
                    "code": null,
                    "message": "Some kind of error happened",
                    "type": "some_error_type"
                }
            }"#,
            )
            .create();
        let expected = api::ErrorMessage {
            message: "Some kind of error happened".into(),
            error_type: "some_error_type".into(),
        };
        let response = mocked_client().engine("davinci").await;
        if let Result::Err(Error::Api(msg)) = response {
            assert_eq!(expected, msg);
        }
        mock.assert();
    }

    #[cfg(feature = "is_async")]
    #[tokio::test]
    async fn completion_args() {
        let mock = mockito::mock("POST", "/engines/davinci/completions")
            .with_status(200)
            .with_header("content-type", "application/json")
            .with_body(
                r#"{
                "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
                "object": "text_completion",
                "created": 1589478378,
                "model": "davinci:2020-05-03",
                "choices": [
                    {
                    "text": " there was a girl who",
                    "index": 0,
                    "logprobs": null,
                    "finish_reason": "length"
                    }
                ]
                }"#,
            )
            .expect(1)
            .create();
        let args = api::CompletionArgs::builder()
            .engine("davinci")
            .prompt("Once upon a time")
            .max_tokens(5)
            .temperature(1.0)
            .top_p(1.0)
            .n(1)
            .stop(vec!["\n".into()])
            .build()
            .unwrap();
        let expected = api::Completion {
            id: "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7".into(),
            created: 1589478378,
            model: "davinci:2020-05-03".into(),
            choices: vec![api::Choice {
                text: " there was a girl who".into(),
                index: 0,
                logprobs: None,
                finish_reason: "length".into(),
            }],
        };
        let response = mocked_client().complete_prompt(args).await.unwrap();
        assert_eq!(response.model, expected.model);
        assert_eq!(response.id, expected.id);
        assert_eq!(response.created, expected.created);
        let (a_choice, b_choice) = (&response.choices[0], &expected.choices[0]);
        assert_eq!(a_choice.text, b_choice.text);
        assert_eq!(a_choice.index, b_choice.index);
        assert!(a_choice.logprobs.is_none());
        assert_eq!(a_choice.finish_reason, b_choice.finish_reason);
        mock.assert();
    }
}

#[cfg(test)]
mod integration {
    use crate::{api, Client};
    /// Used by tests to get a client to the actual api
    fn get_client() -> Client {
        let _ = env_logger::builder().is_test(true).try_init();
        let sk = std::env::var("OPENAI_SK").expect(
            "To run integration tests, you must put set the OPENAI_SK env var to your api token",
        );
        Client::new(&sk)
    }
    #[cfg(feature = "is_async")]
    #[tokio::test]
    async fn can_get_engines() {
        let client = get_client();
        let engines = client
            .engines()
            .await
            .unwrap()
            .into_iter()
            .map(|ei| ei.id)
            .collect::<Vec<_>>();
        assert!(engines.contains(&"ada".into()));
        assert!(engines.contains(&"babbage".into()));
        assert!(engines.contains(&"curie".into()));
        assert!(engines.contains(&"davinci".into()));
    }
    #[cfg(feature = "is_sync")]
    #[test]
    fn can_get_engines() {
        let client = get_client();
        let engines = client
            .engines()
            .unwrap()
            .into_iter()
            .map(|ei| ei.id)
            .collect::<Vec<_>>();
        assert!(engines.contains(&"ada".into()));
        assert!(engines.contains(&"babbage".into()));
        assert!(engines.contains(&"curie".into()));
        assert!(engines.contains(&"davinci".into()));
    }

    #[cfg(feature = "is_async")]
    #[tokio::test]
    async fn can_get_engine() {
        let client = get_client();
        let info = client.engine("ada").await.unwrap();
        assert_eq!(info.id, "ada");
        assert!(info.ready);
        assert_eq!(info.owner, "openai");
    }

    #[cfg(feature = "is_async")]
    #[tokio::test]
    async fn complete_string() {
        let client = get_client();
        client.complete_prompt("Hey there").await.unwrap();
    }

    #[cfg(feature = "is_async")]
    #[tokio::test]
    async fn complete_stop_condition() {
        let client = get_client();
        let args = {
            api::CompletionArgs::builder()
                .prompt(
                    r#"
Q: Please type `#` now
A:"#,
                )
                // turn temp & top_p way down to prevent test flakiness
                .temperature(0.0)
                .top_p(0.0)
                .max_tokens(100)
                .stop(vec!["#".into(), "\n".into()])
                .build()
                .expect("Bug: build should succeed")
        };
        let result = &client.complete_prompt(args).await.unwrap().choices[0].finish_reason;
        assert_eq!(result, "stop",);
    }
}
